# -*- coding: utf-8 -*-
"""House_Prices.ipynb

Automatically generated by Colab.



**Goal**: It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable.

> Indented block:

Metric
Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)
"""

# Part 1 - Data Preprocessing

# Import libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

# Import datasets / training set
dataset_train = pd.read_csv('train.csv')
training_set = dataset_train.iloc[:, 1:2].values

# Print columns in train a
#print(dataset_train.columns)
#print(training_set.columns)

#display information from the first 10 and last 10
dataset_train.head()
dataset_train.tail()

dataset_train.describe()

#import preprocessing sklear

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)

#create a for loop with the X_train and y_train
X_train = []
y_train = []

for i in range(60, len(training_set_scaled)):
    X_train.append(training_set_scaled[i-60:i, 0])
    y_train.append(training_set_scaled[i, 0])

X_train, y_train = np.array(X_train), np.array(y_train)

#reshape X_train

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

#import keras

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

regressor = Sequential()

regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))
regressor.add(Dropout(0.2))

#next block
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

#next block
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

#next block
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))

#next block, compile regressor to the batch size
regressor.add(Dense(units = 1, activation='linear'))

regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')

regressor.fit(X_train, y_train, epochs = 10, batch_size = 32)

#next block
dataset_test = pd.read_csv('test.csv')
real_house_prices = dataset_test.iloc[:, 1:2].values

#next block: calculate the stock price for houses
dataset_total = pd.concat((dataset_train['SalePrice'], dataset_test['Id']), axis = 0)
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 80:].values
#inputs = dataset_total.values.reshape(-1, 1)

inputs = sc.transform(inputs)
X_test = []
for i in range(80, 90):
    X_test.append(inputs[i-80:i, 0])

X_test = np.array(X_test)
X_test = X_test.reshape(1, -1)
X_test = X_test.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

predicted_house_price = regressor.predict(X_test)
predicted_house_price = sc.inverse_transform(predicted_house_price)

#next block: create the plot for the house price
plt.plot(real_house_prices, color = 'red', label = 'Real House Price')
plt.plot(predicted_house_price, color = 'blue', label = 'Predicted House Price')
plt.title('Real VS Predicted House Prices')
plt.xlabel('House Price')
plt.legend()
plt.show()

#display columns and rows information
dataset_train.columns

#display shape
dataset_train.shape

#display info
dataset_train.info()

#display sum value
dataset_train.isnull().values.sum()

#display the pair plot using seaborn
sns.pairplot(dataset_train)

#import sklearn
from sklearn.model_selection import train_test_split

#enter the info for X and y

X = []

y = []

#train test split formula

X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.5, random_state=55)

# !pip install tensorflow

#import for deep learning

from tensorflow import keras
from keras.layers import Dense
from keras.models import Sequential

#write the Sequential formula for model and then compile the model

model = Sequential()

model.add(Dense(10, activation = 'relu'))
model.add(Dense(16, activation = 'relu'))
model.add(Dense(8, activation = 'relu'))
model.add(Dense(4, activation = 'relu'))
model.add(Dense(1, activation = 'relu'))

model.compile(loss = 'mean_squared_error',
              optimizer = 'adam') #, metrics = 'accuracy'

#create the fit model
model.fit(X_train, y_train, epochs = 50)

#verify and evaluate the model
model.evaluate(X_test, y_test)

#create a logistics regression
from sklearn.linear_model import LogisticRegression

dataset_test.dropna(inplace = True)

from sklearn.preprocessing import RobustScaler
new_df = dataset_train.copy()
new_df['SalePrice'] = RobustScaler().fit_transform(new_df['SalePrice'].to_numpy().reshape(-1, 1))
time = new_df['YrSold']
new_df['YrSold'] = (time - time.min()) / (time.max() - time.min())
new_df

new_df = new_df.sample(frac = 1, random_state=1)
new_df

train, test, val = new_df[:1460], new_df[1460:2152], new_df[262000:]
train['YrSold'].value_counts(), test['YrSold'].value_counts(), val['YrSold'].value_counts()

train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()
train_np.shape, test_np.shape, val_np.shape

x_train, y_train = train_np[:, :-1], train_np[:, -1]
x_test, y_test = test_np[:, :-1], test_np[:, -1]
x_val, y_val = val_np[:, :-1], val_np[:, -1]
x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape

from sklearn.linear_model import LogisticRegression
logistic_model = LogisticRegression()
logistic_model.fit(x_train, y_train)
logistic_model.score(x_train, y_train)

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_val, logistic_model.predict(x_val))

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(max_depth = 3, n_jobs = 1)
rf.fit(x_train, y_train)
ConfusionMatrixDisplay.from_predictions(y_val, rf.predict(x_val))

from tensorflow import keras
from keras.layers import Dense, InputLayer, BatchNormalization
from keras.models import Sequential, load_model
from keras.callbacks import ModelCheckpoint

shallow_nn = Sequential()
shallow_nn.add(InputLayer((x_train.shape[1],)))
shallow_nn.add(Dense(2, activation='relu'))
shallow_nn.add(BatchNormalization())
shallow_nn.add(Dense(1, activation='sigmoid'))

checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)
shallow_nn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

shallow_nn.summary()

shallow_nn.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 5, callbacks = checkpoint)

def neural_net_predictions(model, x):
  return (model.predict(x).flatten() > 0.5).astype(int)
neural_net_predictions(shallow_nn, x_val)

ConfusionMatrixDisplay.from_predictions(y_val, neural_net_predictions(shallow_nn, x_val))







